import traceback
import sys  # ‚úÖ AJOUT√â ICI
import os  # ‚úÖ AJOUT√â ICI
import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import math
from collections import deque
import warnings
from ta.volatility import average_true_range
from rich.console import Console
from rich.table import Table
from rich.text import Text
import ta

# ‚úÖ MAINTENANT ON PEUT UTILISER sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from src.environment.risk_manager import DynamicRiskManager as RiskManager
from src.tests.monitor_training import TradeLogger
from src.environment.strategy_features import SmartMoneyEngine

# IMPORTANT: Import constants from config.py
try:
    from src.config import (
        LOOKBACK_WINDOW_SIZE, INITIAL_BALANCE, TRANSACTION_FEE_PERCENTAGE,
        TRADE_COMMISSION_PER_TRADE, SLIPPAGE_PERCENTAGE, REWARD_SCALING_FACTOR,
        ALLOW_NEGATIVE_REVENUE_SELL, ALLOW_NEGATIVE_BALANCE, MINIMUM_ALLOWED_BALANCE,
        MIN_TRADE_QUANTITY, ACTION_SPACE_TYPE, FEATURES, OHLCV_COLUMNS,
        DOWNSIDE_PENALTY_MULTIPLIER, OVERNIGHT_HOLDING_PENALTY, HOLD_PENALTY_FACTOR,
        WINNING_TRADE_BONUS, LOSING_TRADE_PENALTY, FAILED_TRADE_ATTEMPT_PENALTY,
        TRADE_COOLDOWN_STEPS, RAPID_TRADE_PENALTY, TRAIN_END_DATE, SMC_CONFIG,
        RISK_PERCENTAGE_PER_TRADE, TAKE_PROFIT_PERCENTAGE, STOP_LOSS_PERCENTAGE,
        TSL_START_PROFIT_MULTIPLIER, TSL_TRAIL_DISTANCE_MULTIPLIER,
        MAX_LEVERAGE, MAX_DURATION_STEPS,
        W_RETURN, W_DRAWDOWN, W_FRICTION, W_LEVERAGE, W_TURNOVER, W_DURATION
    )
except ImportError:
    print("WARNING: Could not import from config. Using production fallback parameters.")

    # ‚úÖ FALLBACK COMPLET CORRIG√â
    TRAIN_END_DATE = "2023-06-30 23:59:00"
    INITIAL_BALANCE = 1000.0
    TRANSACTION_FEE_PERCENTAGE = 0.0005
    SLIPPAGE_PERCENTAGE = 0.0001
    TRADE_COMMISSION_PER_TRADE = 0.0005
    LOOKBACK_WINDOW_SIZE = 60
    RISK_PERCENTAGE_PER_TRADE = 0.01
    TAKE_PROFIT_PERCENTAGE = 0.02
    STOP_LOSS_PERCENTAGE = 0.01
    TSL_START_PROFIT_MULTIPLIER = 1.0
    TSL_TRAIL_DISTANCE_MULTIPLIER = 0.5
    ALLOW_NEGATIVE_REVENUE_SELL = False
    ALLOW_NEGATIVE_BALANCE = False
    MINIMUM_ALLOWED_BALANCE = 100.0
    MIN_TRADE_QUANTITY = 0.01

    # ‚úÖ AJOUT√â: Variables manquantes
    ACTION_SPACE_TYPE = 'discrete'
    OVERNIGHT_HOLDING_PENALTY = 0.0
    HOLD_PENALTY_FACTOR = 0.005
    FAILED_TRADE_ATTEMPT_PENALTY = 0.0

    # Reward Weights
    REWARD_SCALING_FACTOR = 100.0
    W_RETURN = 1.0
    W_DRAWDOWN = 2.0
    W_FRICTION = 0.8
    W_LEVERAGE = 2.0
    W_TURNOVER = 0.1
    W_DURATION = 0.3

    # Penalties and Bonuses
    DOWNSIDE_PENALTY_MULTIPLIER = 3.0
    WINNING_TRADE_BONUS = 2.0
    LOSING_TRADE_PENALTY = 5.0
    TRADE_COOLDOWN_STEPS = 5
    RAPID_TRADE_PENALTY = 5.0
    MAX_LEVERAGE = 1.5
    MAX_DURATION_STEPS = 12  # ‚úÖ CORRIG√â: Supprim√© [cite: 1

    OHLCV_COLUMNS = {
        "timestamp": "Date",
        "open": "Open",
        "high": "High",
        "low": "Low",
        "close": "Close",
        "volume": "Volume"
    }

    SMC_CONFIG = {
        "RSI_WINDOW": 7,
        "MACD_FAST": 8,
        "MACD_SLOW": 17,
        "MACD_SIGNAL": 9,
        "BB_WINDOW": 20,
        "ATR_WINDOW": 7,
        "FRACTAL_WINDOW": 2,
        "FVG_THRESHOLD": 0.0,
    }

    FEATURES = [
        'Open', 'High', 'Low', 'Close', 'Volume',
        'RSI', 'MACD_Diff', 'MACD_line', 'MACD_signal',
        'BB_L', 'BB_M', 'BB_H', 'ATR', 'SPREAD', 'BODY_SIZE',
        'UP_FRACTAL', 'DOWN_FRACTAL', 'FVG_SIGNAL', 'FVG_SIZE_NORM',
        'BOS_SIGNAL', 'CHOCH_SIGNAL', 'BULLISH_OB_HIGH', 'BULLISH_OB_LOW',
        'BEARISH_OB_HIGH', 'BEARISH_OB_LOW', 'OB_STRENGTH_NORM'
    ]

class TradingEnv(gym.Env):
    metadata = {"render_modes": ["human", "none"], "render_fps": 30}
    _gym_reset_return_info = True

    def __init__(self, df: pd.DataFrame, render_mode: str = "none", **kwargs):
        super().__init__()
        self.render_mode = render_mode

        self.lookback_window_size = kwargs.get('lookback_window_size', LOOKBACK_WINDOW_SIZE)
        self.initial_balance = kwargs.get('initial_balance', INITIAL_BALANCE)

        self.transaction_fee_percentage = kwargs.get('transaction_fee_percentage', TRANSACTION_FEE_PERCENTAGE)
        self.trade_commission_per_trade = kwargs.get('trade_commission_per_trade', TRADE_COMMISSION_PER_TRADE)
        self.slippage_percentage = kwargs.get('slippage_percentage', SLIPPAGE_PERCENTAGE)
        self.reward_scaling_factor = kwargs.get('reward_scaling_factor', REWARD_SCALING_FACTOR)
        self.allow_negative_revenue_sell = kwargs.get('allow_negative_revenue_sell', ALLOW_NEGATIVE_REVENUE_SELL)
        self.allow_negative_balance = kwargs.get('allow_negative_balance', ALLOW_NEGATIVE_BALANCE)
        self.minimum_allowed_balance = kwargs.get('minimum_allowed_balance', MINIMUM_ALLOWED_BALANCE)
        self.min_trade_quantity = kwargs.get('min_trade_quantity', MIN_TRADE_QUANTITY)
        self.downside_penalty_multiplier = kwargs.get('downside_penalty_multiplier', DOWNSIDE_PENALTY_MULTIPLIER)
        self.overnight_holding_penalty = kwargs.get('overnight_holding_penalty', OVERNIGHT_HOLDING_PENALTY)
        self.hold_penalty_factor = kwargs.get('hold_penalty_factor', HOLD_PENALTY_FACTOR)
        self.winning_trade_bonus = kwargs.get('winning_trade_bonus', WINNING_TRADE_BONUS)
        self.losing_trade_penalty = kwargs.get('losing_trade_penalty', LOSING_TRADE_PENALTY)
        self.trade_cooldown_steps = kwargs.get('trade_cooldown_steps', TRADE_COOLDOWN_STEPS)
        self.rapid_trade_penalty = kwargs.get('rapid_trade_penalty', RAPID_TRADE_PENALTY)
        self.smc_config = kwargs.get('smc_config', SMC_CONFIG)
        self.features_config = kwargs.get('features', FEATURES)
        self.ohlcv_columns = kwargs.get('ohlcv_columns', OHLCV_COLUMNS)
        self.enable_logging = kwargs.get('enable_logging', False)
        self.trade_logger = TradeLogger() if self.enable_logging else None
        self.trade_id_counter = 0
        self.episode_count = 0
        self.episode_reward = 0.0

        # --- NEW: Reward Weights and Limits (Hyperparameters) ---
        self.max_leverage_limit = kwargs.get('max_leverage_limit', MAX_LEVERAGE)
        # Assurez-vous que cette ligne est pr√©sente dans le __init__
        self.max_duration_steps = kwargs.get('max_duration_steps', MAX_DURATION_STEPS)
        self.w_R = kwargs.get('w_R', W_RETURN)
        self.w_DD = kwargs.get('w_DD', W_DRAWDOWN)
        self.w_F = kwargs.get('w_F', W_FRICTION)
        self.w_L = kwargs.get('w_L', W_LEVERAGE)
        self.w_T = kwargs.get('w_T', W_TURNOVER)
        self.w_D = kwargs.get('w_D', W_DURATION)
        self.debug_rewards = False  # Set to True only for debugging
        # --------------------------------------------------------

        self.risk_manager = RiskManager(config=kwargs)
        self._risk_client_id = kwargs.get('risk_client_id', 'default_client')
        self.risk_manager.set_client_profile(
            client_id=self._risk_client_id,
            initial_equity=self.initial_balance,
            max_drawdown_pct=kwargs.get('max_drawdown_pct', 20.0),  # 20% MDD default
            kelly_fraction_limit=kwargs.get('kelly_fraction_limit', 0.1),  # 10% cap by default
            max_trade_risk_pct=kwargs.get('max_trade_risk_pct', 0.01)  # 1% per trade default
        )
        self.trade_commission_pct_of_trade = kwargs.get(
            'trade_commission_pct_of_trade',
            0.0005  # 0.05% du trade value (standard broker)
        )

        self.trade_commission_min_pct_capital = kwargs.get(
            'trade_commission_min_pct_capital',
            0.0001  # 0.01% du capital initial minimum
        )

        self.df_raw = df.copy()

        self.processed_data = self._process_data(self.df_raw)
        self.df = self.processed_data
        self.features = [col for col in self.features_config if col in self.df.columns]
        if 'Close' not in self.df.columns and 'close' in self.df.columns:
            self.df.rename(columns={'close': 'Close'}, inplace=True)
        if 'Close' not in self.df.columns:
            raise ValueError("Processed DataFrame must contain a 'Close' price column.")

        if len(self.df) <= self.lookback_window_size:
            raise ValueError(
                f"Pas assez de donn√©es (longueur: {len(self.df)}) pour une fen√™tre de {self.lookback_window_size}."
            )

        self.balance = self.initial_balance
        self.stock_quantity = 0.0
        self.net_worth = self.initial_balance
        self.total_fees_paid = 0.0
        self.current_step = self.lookback_window_size
        self.max_steps = len(self.df) - 1
        self.entry_price = np.nan

        # --- NEW: State tracking variables for advanced reward function ---
        self.previous_nav = self.initial_balance
        self.peak_nav = self.initial_balance
        self.previous_drawdown_level = 0.0
        self.current_leverage = 0.0
        self.current_hold_duration = 0
        self.transaction_cost_incurred_step = 0.0
        self.traded_value_step = 0.0
        # ------------------------------------------------------------------

        self.trade_details = {'trade_pnl_abs': 0.0, 'trade_pnl_pct': 0.0, 'trade_type': 'none', 'trade_success': False,
                              'trade_value': 0.0, 'commission': 0.0}
        self.trade_history_summary = []
        self.winning_trades = 0
        self.losing_trades = 0
        self.total_trades = 0
        self.total_fees_paid_episode = 0.0
        self.np_random = np.random.default_rng()
        self.last_action = 0
        self.actual_action_executed = 0
        self.last_trade_step = -np.inf
        self.recent_trade_attempts_steps = deque(maxlen=self.lookback_window_size)

        self.scaler = MinMaxScaler()
        valid_rows = self.df[self.features].dropna()

        if not valid_rows.empty:
            self.scaler.fit(valid_rows.values)
        else:
            warnings.warn("No valid rows for scaling. Check feature generation pipeline.")
            self.scaler = None
        action_space_type = kwargs.get('action_space_type', ACTION_SPACE_TYPE)
        if action_space_type == "discrete":
            self.action_space = spaces.Discrete(3)
        else:
            raise ValueError(f"Type d'espace d'action invalide: {action_space_type}")

        num_features_per_step = len(self.features)
        expected_obs_size = num_features_per_step * self.lookback_window_size + 3
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(expected_obs_size,), dtype=np.float32)

        self.reset()

    def _process_data(self, df_raw: pd.DataFrame) -> pd.DataFrame:
        """
        Traite les donn√©es brutes OHLCV et g√©n√®re les features techniques et SMC.
        VERSION PRODUCTION-READY avec gestion intelligente des NaN et validation.
        """

        # =========================================================================
        # √âTAPE 1: PR√âPARATION ET NORMALISATION DES COLONNES
        # =========================================================================

        df = df_raw.copy()

        # Pr√©server l'horodatage original
        if df_raw.index.name is not None:
            df = df.reset_index()

        # Identifier et renommer la colonne de date
        date_col_name = str(df.columns[0])
        df.rename(columns={date_col_name: 'Original_Timestamp'}, inplace=True)

        # Normaliser les colonnes OHLCV en minuscules (sauf Original_Timestamp)
        df.columns = [col.lower() if col != 'Original_Timestamp' else col for col in df.columns]

        # Validation des colonnes essentielles
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"‚ùå Colonnes OHLCV manquantes: {missing_cols}")

        # =========================================================================
        # √âTAPE 2: G√âN√âRATION DES FEATURES (TA + SMC)
        # =========================================================================

        try:
            engine = SmartMoneyEngine(data=df, config=self.smc_config)
            df_processed = engine.analyze()
            print(f"‚úÖ SmartMoneyEngine: {len(df_processed)} lignes g√©n√©r√©es")
        except Exception as e:
            print(f"‚ùå Erreur SmartMoneyEngine: {e}")
            raise

        # =========================================================================
        # √âTAPE 3: NORMALISATION DES COLONNES (Capitalisation)
        # =========================================================================

        # Capitaliser les colonnes OHLCV pour coh√©rence avec le reste du code
        df_processed.columns = [
            c.capitalize() if c.lower() in ['open', 'high', 'low', 'close', 'volume']
            else c for c in df_processed.columns
        ]

        # Assurer la pr√©sence de 'Close' (colonne critique)
        if 'close' in df_processed.columns and 'Close' not in df_processed.columns:
            df_processed.rename(columns={'close': 'Close'}, inplace=True)

        # Assurer la pr√©sence de 'ATR' (indicateur critique pour RiskManager)
        if 'ATR' not in df_processed.columns:
            if 'atr' in df_processed.columns:
                df_processed.rename(columns={'atr': 'ATR'}, inplace=True)
            else:
                print("‚ö†Ô∏è WARNING: ATR manquant. Calcul de fallback...")
                df_processed['ATR'] = ta.volatility.average_true_range(
                    df_processed['High'],
                    df_processed['Low'],
                    df_processed['Close'],
                    window=self.smc_config.get('ATR_WINDOW', 14)
                )

        # =========================================================================
        # √âTAPE 4: NETTOYAGE DES INFINIT√âS
        # =========================================================================

        df_processed.replace([np.inf, -np.inf], np.nan, inplace=True)
        print(f"üßπ Infinit√©s remplac√©es par NaN")

        # =========================================================================
        # √âTAPE 5: GESTION INTELLIGENTE DES NaN (CRITIQUE!)
        # =========================================================================

        print("\nüîç Analyse des NaN avant nettoyage:")
        nan_summary = df_processed.isna().sum()
        nan_summary = nan_summary[nan_summary > 0].sort_values(ascending=False)
        if not nan_summary.empty:
            print(nan_summary)

        # --- 5.1: SUPPRESSION DES LIGNES AVEC NaN CRITIQUES ---
        # Ces colonnes ne peuvent PAS contenir de NaN (risque de crash)
        essential_features = [
            'Open', 'High', 'Low', 'Close',  # Prix
            'RSI',  # Momentum critique
            'MACD_line',  # Tendance critique
            'ATR'  # Volatilit√© critique
        ]

        rows_before = len(df_processed)
        df_processed.dropna(
            subset=[f for f in essential_features if f in df_processed.columns],
            inplace=True
        )
        rows_dropped = rows_before - len(df_processed)

        if rows_dropped > 0:
            print(f"‚ö†Ô∏è {rows_dropped} lignes supprim√©es (NaN dans colonnes critiques)")

        # Validation post-suppression
        if len(df_processed) < self.lookback_window_size * 2:
            raise ValueError(
                f"‚ùå Pas assez de donn√©es apr√®s nettoyage: {len(df_processed)} lignes "
                f"(minimum requis: {self.lookback_window_size * 2})"
            )

        # --- 5.2: FORWARD/BACKWARD FILL POUR INDICATEURS LENTS ---
        # Ces indicateurs peuvent √™tre interpol√©s de mani√®re s√©curis√©e
        slow_indicators = [
            'RSI', 'MACD_line', 'MACD_signal', 'MACD_Diff',
            'BB_L', 'BB_M', 'BB_H', 'ATR'
        ]

        for col in slow_indicators:
            if col in df_processed.columns:
                # Forward fill (propagation de la derni√®re valeur connue)
                df_processed[col] = df_processed[col].ffill()
                # Backward fill pour les premi√®res valeurs (si n√©cessaire)
                df_processed[col] = df_processed[col].bfill()

        print(f"‚úÖ Indicateurs lents interpol√©s: {slow_indicators}")

        # --- 5.3: REMPLISSAGE PAR 0 POUR SIGNAUX SMC ---
        # Ces colonnes sont des signaux √©v√©nementiels: NaN = "Pas de signal" = 0
        smc_signal_cols = [
            'FVG_SIGNAL',  # Fair Value Gap signal
            'FVG_SIZE_NORM',  # Taille FVG normalis√©e
            'BOS_SIGNAL',  # Break of Structure
            'CHOCH_SIGNAL',  # Change of Character
            'OB_STRENGTH_NORM',  # Force Order Block
            'UP_FRACTAL',  # Swing High
            'DOWN_FRACTAL',  # Swing Low
            'BULLISH_OB_HIGH',  # Zone Order Block haussier
            'BULLISH_OB_LOW',
            'BEARISH_OB_HIGH',  # Zone Order Block baissier
            'BEARISH_OB_LOW'
        ]

        for col in smc_signal_cols:
            if col in df_processed.columns:
                df_processed[col] = df_processed[col].fillna(0.0)

        print(
            f"‚úÖ Signaux SMC initialis√©s √† 0: {len([c for c in smc_signal_cols if c in df_processed.columns])} colonnes")

        # --- 5.4: REMPLISSAGE PAR M√âDIANE POUR LE VOLUME ---
        # Le volume peut varier √©norm√©ment, la m√©diane est plus robuste que 0
        if 'Volume' in df_processed.columns:
            volume_median = df_processed['Volume'].median()
            nan_count = df_processed['Volume'].isna().sum()
            if nan_count > 0:
                df_processed['Volume'] = df_processed['Volume'].fillna(volume_median)
                print(f"‚úÖ Volume: {nan_count} NaN remplac√©s par m√©diane ({volume_median:.0f})")

        # --- 5.5: REMPLISSAGE FINAL (S√âCURIT√â) ---
        # Si des colonnes ont encore des NaN, on remplace par 0 (dernier recours)
        remaining_cols_with_nan = df_processed.columns[df_processed.isna().any()].tolist()

        if remaining_cols_with_nan:
            print(f"‚ö†Ô∏è Colonnes avec NaN restants: {remaining_cols_with_nan}")
            df_processed[remaining_cols_with_nan] = df_processed[remaining_cols_with_nan].fillna(0.0)

        # =========================================================================
        # √âTAPE 6: VALIDATION FINALE DE LA QUALIT√â DES DONN√âES
        # =========================================================================

        # V√©rifier qu'il ne reste AUCUN NaN
        final_nan_count = df_processed.isna().sum().sum()
        if final_nan_count > 0:
            raise ValueError(f"‚ùå {final_nan_count} NaN restants apr√®s nettoyage complet!")

        # V√©rifier qu'il ne reste AUCUNE infinit√©
        inf_count = np.isinf(df_processed.select_dtypes(include=[np.number])).sum().sum()
        if inf_count > 0:
            raise ValueError(f"‚ùå {inf_count} valeurs infinies d√©tect√©es!")

        # V√©rifier la pr√©sence de prix aberrants (0 ou n√©gatifs)
        if (df_processed['Close'] <= 0).any():
            invalid_prices = (df_processed['Close'] <= 0).sum()
            raise ValueError(f"‚ùå {invalid_prices} prix invalides (‚â§0) d√©tect√©s!")

        # V√©rifier la d√©tection de mouvements extr√™mes (flash crash potentiel)
        price_changes = df_processed['Close'].pct_change().abs()
        extreme_moves = (price_changes > 0.2).sum()  # Mouvements >20%
        if extreme_moves > 0:
            print(f"‚ö†Ô∏è WARNING: {extreme_moves} mouvements de prix >20% d√©tect√©s (v√©rifier donn√©es)")

        # Reset index pour un DataFrame propre
        df_processed.reset_index(drop=True, inplace=True)

        # =========================================================================
        # √âTAPE 7: RAPPORT FINAL
        # =========================================================================

        print("\n" + "=" * 70)
        print("üìä RAPPORT DE TRAITEMENT DES DONN√âES")
        print("=" * 70)
        print(f"‚úÖ Lignes finales:        {len(df_processed)}")
        print(f"‚úÖ Colonnes totales:      {len(df_processed.columns)}")
        print(f"‚úÖ NaN restants:          {df_processed.isna().sum().sum()}")
        print(f"‚úÖ Valeurs infinies:      {np.isinf(df_processed.select_dtypes(include=[np.number])).sum().sum()}")
        print(f"‚úÖ P√©riode couverte:      {df_processed.index[0]} ‚Üí {df_processed.index[-1]}")

        # Afficher les features disponibles
        feature_categories = {
            'Prix': ['Open', 'High', 'Low', 'Close', 'Volume'],
            'Indicateurs TA': ['RSI', 'MACD_line', 'MACD_signal', 'MACD_Diff', 'BB_L', 'BB_M', 'BB_H', 'ATR'],
            'SMC Signaux': ['BOS_SIGNAL', 'CHOCH_SIGNAL', 'FVG_SIGNAL', 'UP_FRACTAL', 'DOWN_FRACTAL'],
            'SMC Zones': ['BULLISH_OB_HIGH', 'BULLISH_OB_LOW', 'BEARISH_OB_HIGH', 'BEARISH_OB_LOW']
        }

        print("\nüìã Features disponibles par cat√©gorie:")
        for category, features in feature_categories.items():
            available = [f for f in features if f in df_processed.columns]
            print(f"  {category}: {len(available)}/{len(features)} ‚Üí {available}")

        print("=" * 70 + "\n")

        return df_processed

    def _get_obs(self) -> np.ndarray:
        """
        Returns the flattened observation vector for the current environment step.
        Includes scaled feature window and normalized portfolio state metrics.
        """

        # --- 1. Extract lookback window safely ---
        start_idx = self.current_step - self.lookback_window_size + 1
        obs_df = self.df.iloc[max(0, start_idx):self.current_step + 1].copy()

        # Padding (if the window is smaller than required)
        if len(obs_df) < self.lookback_window_size:
            padding_needed = self.lookback_window_size - len(obs_df)
            padded_data = np.zeros((padding_needed, len(self.df.columns)))
            padded_df = pd.DataFrame(padded_data, columns=self.df.columns)
            obs_df = pd.concat([padded_df, obs_df], ignore_index=True)

        # Keep the last lookback_window_size rows only
        obs_df = obs_df.tail(self.lookback_window_size)

        # --- 2. Feature extraction ---
        features_data = obs_df[self.features].values

        # --- 3. Scaling ---
        if self.scaler is not None:
            scaled_features = self.scaler.transform(features_data)
        else:
            scaled_features = features_data
            warnings.warn("‚ö†Ô∏è Scaler is None ‚Äî features are not normalized.")

        flat_obs = scaled_features.flatten()

        # --- 4. Portfolio state extraction ---
        # Force scalar conversion to avoid ambiguous truth values
        # --- 4. Portfolio state extraction ---
        step_index = int(self.current_step)
        current_price = float(np.atleast_1d(self.df["Close"].iloc[step_index])[0])

        current_equity = float(self.balance + self.stock_quantity * current_price)

        # --- 5. Leverage calculation ---
        total_position_value = float(self.stock_quantity * current_price)
        if current_equity > 1e-9:
            self.current_leverage = total_position_value / current_equity
        else:
            self.current_leverage = 0.0

        # --- 6. Normalized financial metrics ---
        normalized_balance = float(self.balance / self.initial_balance)
        normalized_net_worth = float(current_equity / self.initial_balance)
        normalized_stock_quantity = float(total_position_value / self.initial_balance)

        # --- 7. Concatenate into a single observation vector ---
        observation = np.append(
            flat_obs, [normalized_balance, normalized_stock_quantity, normalized_net_worth]
        )

        # --- 8. Shape and value validation ---
        expected_size = len(self.features) * self.lookback_window_size + 3
        if observation.shape[0] != expected_size:
            warnings.warn(
                f"‚ö†Ô∏è Observation shape mismatch: expected {expected_size}, got {observation.shape[0]}."
            )

        if np.isnan(observation).any() or np.isinf(observation).any():
            bad_cols = obs_df[self.features].columns[
                np.isnan(obs_df[self.features].values).any(axis=0)
            ].tolist()
            raise ValueError(
                f"üö´ Observation contains NaN/Inf at step {self.current_step} "
                f"in columns: {bad_cols}"
            )

        return observation

    def _get_info(self) -> dict:
        current_price = self.df.iloc[self.current_step]['Close']
        self.net_worth = self.balance + self.stock_quantity * current_price
        self.total_trades = self.winning_trades + self.losing_trades
        current_return_percentage = ((self.net_worth - self.initial_balance) / self.initial_balance) * 100 \
            if self.initial_balance > 0 else 0.0

        info = {
            'balance': self.balance,
            'stock_quantity': self.stock_quantity,
            'net_worth': self.net_worth,
            'current_price': current_price,
            'total_trades': self.total_trades,
            'winning_trades': self.winning_trades,
            'losing_trades': self.losing_trades,
            'total_fees_paid': self.total_fees_paid_episode,
            'current_step': self.current_step,
            'episode_return_percentage': current_return_percentage,
            'entry_price': self.entry_price if not math.isclose(self.stock_quantity, 0.0, abs_tol=1e-9) else np.nan,
            'current_sl': self.risk_manager.current_stop_loss,
            'current_tp': self.risk_manager.current_take_profit,
            'actual_action_executed': self.actual_action_executed
        }
        info['trade_details'] = self.trade_details
        return info

    def _execute_trade(self, trade_type: str, trade_price: float, trade_quantity: float):
        """
        Ex√©cute un trade (BUY ou SELL) avec gestion des co√ªts de transaction.

        VERSION CORRIG√âE - Capital-Agnostic:
        - Commission relative au capital (scalable de $100 √† $100K+)
        - Frais proportionnels au trade value
        - Validation robuste des montants
        - Compatible avec tous les niveaux de capital

        Args:
            trade_type (str): 'buy' ou 'sell'
            trade_price (float): Prix d'ex√©cution actuel du march√©
            trade_quantity (float): Quantit√© √† trader (en lots)

        Returns:
            tuple: (trade_success, effective_trade_value, commission, pnl_abs, pnl_pct)
                - trade_success (bool): True si le trade a √©t√© ex√©cut√©
                - effective_trade_value (float): Valeur brute du trade
                - commission (float): Commission totale pay√©e
                - pnl_abs (float): P&L absolu en $ (pour SELL uniquement)
                - pnl_pct (float): P&L en % (pour SELL uniquement)
        """

        # =========================================================================
        # INITIALISATION
        # =========================================================================
        trade_success = False
        effective_trade_value = 0.0
        commission = 0.0
        pnl_abs = 0.0
        pnl_pct = 0.0

        # Reset du tracking des co√ªts pour ce step
        self.traded_value_step = 0.0
        self.transaction_cost_incurred_step = 0.0

        try:
            # =====================================================================
            # BUY LOGIC
            # =====================================================================
            if trade_type == 'buy':
                # --- 1. Calcul du prix effectif avec spread et slippage ---
                # Le prix d'achat inclut le spread (d√©favorable pour l'acheteur)
                price_with_spread = trade_price * (1 + self.transaction_fee_percentage)
                effective_buy_price = price_with_spread * (1 + self.slippage_percentage)

                # --- 2. Valeur brute du trade (avant commission) ---
                gross_trade_value = effective_buy_price * trade_quantity

                # --- 3. NOUVEAU: Calcul de la commission relative (Capital-Agnostic) ---
                #
                # Commission compos√©e de 2 parties:
                # a) Commission proportionnelle au trade (% de la valeur)
                # b) Commission minimum bas√©e sur le capital (pour √©viter trades trop petits)

                # a) Commission du trade (ex: 0.05% de $1,000 = $0.50)
                commission_pct_trade = getattr(self, 'trade_commission_pct_of_trade', 0.0005)
                commission_from_trade = gross_trade_value * commission_pct_trade

                # b) Commission minimum relative au capital (ex: 0.01% de $1,000 = $0.10)
                commission_min_pct = getattr(self, 'trade_commission_min_pct_capital', 0.0001)
                commission_minimum = self.initial_balance * commission_min_pct

                # La commission finale est le MAXIMUM des deux (prot√®ge contre trades trop petits)
                commission = max(commission_from_trade, commission_minimum)

                # --- 4. Co√ªt total de l'achat ---
                total_cost = gross_trade_value + commission

                # --- 5. Validation: V√©rifier si le trade est possible ---
                # Condition 1: Balance suffisante
                if self.balance < total_cost:
                    self.transaction_cost_incurred_step = 0.0
                    return False, 0.0, 0.0, 0.0, 0.0

                # Condition 2: Quantit√© minimale respect√©e
                if trade_quantity < self.min_trade_quantity:
                    self.transaction_cost_incurred_step = 0.0
                    return False, 0.0, 0.0, 0.0, 0.0

                # --- 6. Ex√©cution du trade ---
                self.balance -= total_cost
                self.stock_quantity += trade_quantity
                self.entry_price = trade_price  # Prix d'entr√©e (utilis√© pour calculer P&L)

                # --- 7. Mise √† jour des compteurs ---
                self.total_fees_paid_episode += commission
                self.transaction_cost_incurred_step = commission
                effective_trade_value = trade_price * trade_quantity  # Valeur "propre" sans frais
                self.traded_value_step = effective_trade_value

                trade_success = True

                # --- 8. Logging optionnel ---
                if hasattr(self, 'verbose') and self.verbose:
                    print(f"‚úÖ BUY Executed: {trade_quantity:.4f} @ ${trade_price:,.2f} | "
                          f"Cost: ${total_cost:,.2f} (Commission: ${commission:.2f})")

            # =====================================================================
            # SELL LOGIC
            # =====================================================================
            elif trade_type == 'sell':
                # --- 1. Validation: V√©rifier si on a assez de stock ---
                if self.stock_quantity < trade_quantity or self.stock_quantity <= 1e-9:
                    self.transaction_cost_incurred_step = 0.0
                    return False, 0.0, 0.0, 0.0, 0.0

                # --- 2. Calcul du prix effectif avec spread et slippage ---
                # Le prix de vente subit le spread (d√©favorable pour le vendeur)
                price_with_spread = trade_price * (1 - self.transaction_fee_percentage)
                effective_sell_price = price_with_spread * (1 - self.slippage_percentage)

                # --- 3. Valeur brute du trade ---
                gross_trade_value = effective_sell_price * trade_quantity

                # --- 4. NOUVEAU: Calcul de la commission relative ---
                commission_pct_trade = getattr(self, 'trade_commission_pct_of_trade', 0.0005)
                commission_from_trade = gross_trade_value * commission_pct_trade

                commission_min_pct = getattr(self, 'trade_commission_min_pct_capital', 0.0001)
                commission_minimum = self.initial_balance * commission_min_pct

                commission = max(commission_from_trade, commission_minimum)

                # --- 5. Revenu net apr√®s commission ---
                total_revenue = gross_trade_value - commission

                # --- 6. Calcul du P&L (Profit & Loss) ---
                if not np.isnan(self.entry_price) and not math.isclose(self.entry_price, 0.0):
                    # Co√ªt d'acquisition (prix d'achat * quantit√©)
                    asset_cost = self.entry_price * trade_quantity

                    # P&L absolu = Revenu - Co√ªt
                    pnl_abs = total_revenue - asset_cost

                    # P&L en pourcentage
                    pnl_pct = (pnl_abs / asset_cost) * 100 if asset_cost > 1e-9 else 0.0
                else:
                    # Cas anormal: pas de prix d'entr√©e enregistr√©
                    pnl_abs = 0.0
                    pnl_pct = 0.0

                # --- 7. Ex√©cution du trade ---
                self.balance += total_revenue
                self.stock_quantity -= trade_quantity

                # --- 8. Si position compl√®tement ferm√©e, reset ---
                if math.isclose(self.stock_quantity, 0.0, abs_tol=1e-9):
                    self.entry_price = np.nan
                    self.stock_quantity = 0.0  # Forcer √† z√©ro exact

                    # Reset du risk manager (SL/TP)
                    if hasattr(self, 'risk_manager') and self.risk_manager is not None:
                        self.risk_manager.reset()

                # --- 9. Mise √† jour des compteurs ---
                self.total_fees_paid_episode += commission
                self.transaction_cost_incurred_step = commission
                effective_trade_value = trade_price * trade_quantity
                self.traded_value_step = effective_trade_value

                trade_success = True

                # --- 10. Logging optionnel ---
                if hasattr(self, 'verbose') and self.verbose:
                    pnl_symbol = "+" if pnl_abs >= 0 else ""
                    print(f"‚úÖ SELL Executed: {trade_quantity:.4f} @ ${trade_price:,.2f} | "
                          f"Revenue: ${total_revenue:,.2f} | P&L: {pnl_symbol}${pnl_abs:.2f} ({pnl_pct:+.2f}%)")

            else:
                # Type de trade invalide
                raise ValueError(f"Invalid trade_type: {trade_type}. Must be 'buy' or 'sell'.")

        except Exception as e:
            # =====================================================================
            # GESTION DES ERREURS
            # =====================================================================
            print(f"‚ùå ERROR _EXECUTE_TRADE: An error occurred during {trade_type.upper()} execution: {e}")
            traceback.print_exc()

            # Reset des co√ªts en cas d'√©chec
            self.transaction_cost_incurred_step = 0.0
            self.traded_value_step = 0.0

            # Retourner des valeurs par d√©faut (trade √©chou√©)
            return False, 0.0, 0.0, 0.0, 0.0

        # =========================================================================
        # RETOUR
        # =========================================================================
        return trade_success, effective_trade_value, commission, pnl_abs, pnl_pct

    def step(self, action: int):
        # --- 1. Track previous state for reward calculation ---
        previous_net_worth = self.net_worth
        self.previous_drawdown_level = self.peak_nav - previous_net_worth
        self.transaction_cost_incurred_step = 0.0
        self.traded_value_step = 0.0

        self.current_step += 1
        done = False
        truncated = False

        # --- End of episode condition ---
        if self.current_step >= self.max_steps:
            truncated = True
            done = True
            if self.stock_quantity > self.min_trade_quantity:
                action = 2  # force sell if still holding
            else:
                action = 0  # hold

        # --- LECTURE CRITIQUE DES DONN√âES (Extraction des floats) ---
        current_row = self.df.iloc[self.current_step]
        current_market_price = float(current_row['Close'])
        current_atr = float(current_row['ATR'])
        bos_signal = float(current_row['BOS_SIGNAL'])

        is_long_position = self.stock_quantity > 0

        # --- Update risk manager regime ---
        regime_state = 0 if bos_signal != 0 else 1
        self.risk_manager.market_state['current_regime'] = regime_state

        # --- NOUVEAU : FILTRE DE CONFIANCE STRAT√âGIQUE (VETO DE L'IA) ---
        if action == 1 and regime_state == 1 and not is_long_position:
            action = 0
            self.actual_action_executed = 6
            self.trade_details['trade_type'] = 'buy_veto_low_confidence'
        elif action == 0 and regime_state == 0 and not is_long_position:
            pass

        # --- Initialize trade details ---
        self.trade_details = {
            'trade_pnl_abs': 0.0, 'trade_pnl_pct': 0.0, 'trade_type': 'hold',
            'trade_success': False, 'trade_value': 0.0, 'commission': 0.0
        }
        self.last_action = action
        self.actual_action_executed = action

        # --- Check for active position and potential exit (SL/TP/TSL) ---
        if not done and self.stock_quantity > 1e-9 and not np.isnan(self.entry_price):
            self.current_hold_duration += 1
            self.risk_manager.update_trailing_stop(self.entry_price, current_market_price, current_atr, is_long=True)
            exit_signal = self.risk_manager.check_trade_exit(current_market_price, is_long=True)
            if exit_signal == 'TP':
                action = 2
                self.actual_action_executed = 3
            elif exit_signal == 'SL':
                action = 2
                self.actual_action_executed = 4
        else:
            self.current_hold_duration = 0

        # --- Cooldown enforcement ---
        if action in [1, 2]:
            if (self.current_step - self.last_trade_step) < self.trade_cooldown_steps:
                self.actual_action_executed = 0
                self.trade_details['trade_type'] = 'hold_cooldown'
                action = 0

        # --- Execute trade logic ---
        trade_executed = False
        if not done:
            # =======================
            # BUY (Action == 1)
            # =======================
            if action == 1:
                sl_distance_abs = self.risk_manager.set_trade_orders(current_market_price, current_atr, is_long=True)

                trade_quantity_calc = self.risk_manager.calculate_adaptive_position_size(
                    client_id=getattr(self, "_risk_client_id", "default_client"),
                    account_equity=self.balance,
                    atr_stop_distance=sl_distance_abs,
                    win_prob=0.5,
                    risk_reward_ratio=1.0
                )

                try:
                    trade_quantity_calc = float(trade_quantity_calc)
                except Exception:
                    trade_quantity_calc = 0.0

                if trade_quantity_calc < self.min_trade_quantity:
                    trade_quantity_calc = 0.0

                estimated_cost = current_market_price * trade_quantity_calc * (
                        1 + self.transaction_fee_percentage + self.slippage_percentage
                )
                if estimated_cost > self.balance and estimated_cost > 0:
                    scale = self.balance / estimated_cost
                    trade_quantity_calc *= scale

                if trade_quantity_calc < self.min_trade_quantity:
                    trade_quantity_calc = 0.0

                if trade_quantity_calc > 0:
                    trade_success, value, commission, pnl_abs, pnl_pct = self._execute_trade(
                        'buy', current_market_price, trade_quantity=trade_quantity_calc
                    )
                    if trade_success:
                        trade_executed = True
                        self.last_trade_step = self.current_step
                        self.trade_details.update({
                            'trade_success': True, 'trade_type': 'buy',
                            'trade_value': value, 'commission': commission,
                            'trade_pnl_abs': pnl_abs, 'trade_pnl_pct': pnl_pct,
                            'quantity': trade_quantity_calc
                        })
                        self.current_hold_duration = 1

                        # --- NOUVEAU: Logger le trade BUY ---
                        if self.trade_logger:
                            self.trade_id_counter += 1
                            self.trade_logger.log_trade({
                                'trade_id': self.trade_id_counter,
                                'trade_type': 'buy',
                                'step': self.current_step,
                                'price': current_market_price,
                                'quantity': trade_quantity_calc,
                                'balance': self.balance,
                                'net_worth': self.net_worth
                            })
                    else:
                        self.trade_details['trade_type'] = 'buy_failed'
                        self.actual_action_executed = 0
                else:
                    self.trade_details['trade_type'] = 'buy_failed'
                    self.actual_action_executed = 0

            # =======================
            # SELL (Action == 2)
            # =======================
            elif action == 2:
                if self.stock_quantity > self.min_trade_quantity:
                    trade_success, value, commission, pnl_abs, pnl_pct = self._execute_trade(
                        'sell', current_market_price, self.stock_quantity
                    )
                    if trade_success:
                        trade_executed = True
                        self.last_trade_step = self.current_step
                        self.trade_history_summary.append({
                            'step': self.current_step,
                            'pnl_abs': pnl_abs, 'pnl_pct': pnl_pct, 'type': 'sell'
                        })
                        self.total_trades += 1
                        if pnl_abs > 0:
                            self.winning_trades += 1
                        else:
                            self.losing_trades += 1
                        self.current_hold_duration = 0

                        # --- NOUVEAU: Logger le trade SELL ---
                        if self.trade_logger:
                            self.trade_logger.log_trade({
                                'trade_id': self.trade_id_counter,
                                'trade_type': 'sell',
                                'step': self.current_step,
                                'price': current_market_price,
                                'quantity': self.stock_quantity,
                                'pnl_abs': pnl_abs,
                                'pnl_pct': pnl_pct,
                                'balance': self.balance,
                                'net_worth': self.net_worth,
                                'duration_bars': self.current_hold_duration
                            })
                    else:
                        self.trade_details['trade_type'] = 'sell_failed'
                else:
                    self.actual_action_executed = 0
                    self.trade_details['trade_type'] = 'hold_no_stock_to_sell'

            # =======================
            # HOLD (Action == 0)
            # =======================
            else:
                self.trade_details['trade_type'] = 'hold'
                self.actual_action_executed = 0

        # --- Portfolio update ---
        self.net_worth = self.balance + (self.stock_quantity * current_market_price)

        # --- Update Drawdown and Leverage Trackers ---
        self.peak_nav = max(self.peak_nav, self.net_worth)

        position_value = self.stock_quantity * current_market_price
        if self.net_worth > 1e-9:
            self.current_leverage = position_value / self.net_worth
        else:
            self.current_leverage = 0.0

        if self.net_worth <= self.minimum_allowed_balance:
            done = True

        # --- Calculate reward ---
        reward = self._calculate_reward(previous_net_worth)
        self.episode_reward += reward  # NOUVEAU: Accumuler le reward de l‚Äô√©pisode

        observation = self._get_obs()
        info = self._get_info()

        self.previous_nav = self.net_worth

        return observation, reward, done, truncated, info

    def _calculate_reward(self, previous_net_worth: float) -> float:
        """
        PRODUCTION-GRADE REWARD FUNCTION FOR PPO TRADING BOT
        =====================================================

        Research-backed design for stable learning and commercial viability.

        Key Improvements:
        - Consistent scaling (no extreme values like -5M)
        - Smooth gradients for stable PPO learning
        - Non-redundant penalties
        - Risk-adjusted profitability focus
        - Commercial viability optimization

        Expected reward range: [-20, +20]
        Typical rewards: [-5, +5]

        Returns:
            float: Scaled reward for PPO training
        """

        # =========================================================================
        # STEP 1: VALIDATION (Prevent Division by Zero)
        # =========================================================================
        if previous_net_worth <= 1e-9 or self.net_worth <= 1e-9:
            # Critical failure: Account depleted
            return -20.0

        # =========================================================================
        # STEP 2: CORE PROFITABILITY METRIC (Most Important Component)
        # =========================================================================
        # Use logarithmic returns for numerical stability (research-backed)
        # log(1.01) ‚âà 0.01 for small changes, but stable for large changes
        log_return = np.log(self.net_worth / previous_net_worth)

        # Scale to interpretable range: 1% gain = ~1.0 reward
        # This provides strong signal for profitable actions
        profitability_reward = log_return * 100.0

        # =========================================================================
        # STEP 3: RISK-ADJUSTED PENALTIES (Prevent Reckless Trading)
        # =========================================================================
        total_penalty = 0.0

        # --- Penalty A: Drawdown Increase (ONLY when WORSENING) ---
        # KEY INSIGHT: Only penalize NEW drawdown, not existing drawdown
        # This prevents the agent from being punished for market conditions
        current_drawdown = self.peak_nav - self.net_worth
        drawdown_increase = max(0.0, current_drawdown - self.previous_drawdown_level)

        if drawdown_increase > 0:
            # Penalty scaled by severity of new drawdown
            # Weight: 5.0 (high priority on capital preservation)
            dd_penalty = (drawdown_increase / self.initial_balance) * 5.0
            total_penalty += dd_penalty

        # --- Penalty B: Transaction Costs (Friction) ---
        # Penalize the direct cost of trading (commission + spread + slippage)
        # This encourages the agent to be selective about trades
        if self.transaction_cost_incurred_step > 0:
            # Weight: 2.0 (moderate - costs are part of business)
            friction_penalty = (self.transaction_cost_incurred_step / self.initial_balance) * 2.0
            total_penalty += friction_penalty

        # --- Penalty C: Leverage Violation (Hard Constraint) ---
        # CRITICAL: Enforce risk management rules
        # Quadratic penalty for exceeding maximum allowed leverage
        leverage_excess = max(0.0, self.current_leverage - self.max_leverage_limit)

        if leverage_excess > 0:
            # Weight: 10.0 (very high - this is a compliance issue)
            # Quadratic scaling: Small violations = small penalty, large = huge
            leverage_penalty = (leverage_excess ** 2) * 10.0
            total_penalty += leverage_penalty

        # --- Penalty D: Excessive Holding Duration ---
        # For daytrading strategy, positions held too long are risky
        # Gentle penalty after exceeding target holding period
        if self.current_hold_duration > self.max_duration_steps:
            duration_excess = self.current_hold_duration - self.max_duration_steps
            # Weight: 0.5 (low - this is a soft constraint)
            duration_penalty = (duration_excess / self.max_duration_steps) * 0.5
            total_penalty += duration_penalty

        # --- Penalty E: Churning (Over-Trading) ---
        # Penalize excessive turnover (trading too frequently)
        # This prevents the agent from becoming a "gambler"
        if self.traded_value_step > 0:
            turnover_ratio = self.traded_value_step / self.net_worth

            # Only penalize if turnover exceeds 50% of account in single step
            if turnover_ratio > 0.5:
                # Weight: 1.0 (moderate - some trading is necessary)
                churn_penalty = (turnover_ratio - 0.5) * 1.0
                total_penalty += churn_penalty

        # =========================================================================
        # STEP 4: COMPOSITE RAW REWARD (Before Normalization)
        # =========================================================================
        raw_reward = profitability_reward - total_penalty

        # =========================================================================
        # STEP 5: SHAPING BONUSES (Learning Signal for Trade Outcomes)
        # =========================================================================
        # These bonuses provide immediate feedback on trade quality
        # Helps the agent learn faster by rewarding good decisions
        bonus = 0.0

        # Check if a trade was just closed (SELL action completed)
        if self.trade_details.get('trade_type') == 'sell' and self.trade_details.get('trade_success'):
            trade_pnl_abs = self.trade_details.get('trade_pnl_abs', 0.0)
            trade_pnl_pct = self.trade_details.get('trade_pnl_pct', 0.0)

            if trade_pnl_abs > 0:
                # === WINNING TRADE ===
                # Bonus scaled by percentage profit (max +2.0)
                win_bonus = min(2.0, (trade_pnl_pct / 100.0) * 10.0)
                bonus += win_bonus

                # Extra bonus for high-quality wins (>1.5% profit)
                # This encourages the agent to wait for good setups
                if trade_pnl_pct > 1.5:
                    bonus += 1.0
            else:
                # === LOSING TRADE ===
                # Small negative feedback (already penalized by profitability)
                # This helps the agent learn to avoid bad trades
                loss_feedback = max(-1.0, (trade_pnl_pct / 100.0) * 5.0)
                bonus += loss_feedback

        # =========================================================================
        # STEP 6: NORMALIZATION (Tanh Squashing)
        # =========================================================================
        # Apply smooth squashing function to prevent extreme values
        # Tanh maps (-‚àû, +‚àû) to (-1, +1) with smooth gradients
        # This is CRITICAL for PPO stability

        combined_reward = raw_reward + bonus

        # Scale factor 0.3: Controls sensitivity
        # Lower = more compressed range, Higher = wider range
        normalized_reward = np.tanh(combined_reward * 0.3)

        # Map to target range: [-5, +5] for typical steps
        scaled_reward = normalized_reward * 5.0

        # =========================================================================
        # STEP 7: SPECIAL CASES (Terminal Conditions)
        # =========================================================================

        # === CRITICAL FAILURE: Account Below Minimum ===
        # This should trigger episode termination with strong penalty
        if self.net_worth <= self.minimum_allowed_balance:
            return -20.0

        # === SEVERE DRAWDOWN: Emergency Risk Management ===
        # If drawdown exceeds 15%, apply additional penalty
        if current_drawdown > 0:
            dd_ratio = current_drawdown / self.peak_nav
            if dd_ratio > 0.15:  # 15% total drawdown
                scaled_reward -= 5.0  # Extra penalty

        # =========================================================================
        # STEP 8: FINAL SAFETY CLIPPING
        # =========================================================================
        # Hard limits to prevent any extreme values that might destabilize training
        # Range: [-20, +20] with most values in [-5, +5]
        final_reward = np.clip(scaled_reward, -20.0, 20.0)

        # =========================================================================
        # STEP 9: OPTIONAL DEBUG LOGGING
        # =========================================================================
        # Enable this during development to understand reward components
        # DISABLE in production for performance
        if hasattr(self, 'debug_rewards') and self.debug_rewards:
            print(f"[REWARD DEBUG] Step {self.current_step}")
            print(f"  Profitability: {profitability_reward:+.3f}")
            print(f"  Total Penalty: {total_penalty:.3f}")
            print(f"    - Drawdown: {dd_penalty if drawdown_increase > 0 else 0:.3f}")
            print(f"    - Friction: {friction_penalty if self.transaction_cost_incurred_step > 0 else 0:.3f}")
            print(f"    - Leverage: {leverage_penalty if leverage_excess > 0 else 0:.3f}")
            print(f"  Bonus: {bonus:+.3f}")
            print(f"  Raw Reward: {raw_reward:+.3f}")
            print(f"  Final Reward: {final_reward:+.3f}")
            print(f"  Net Worth: ${self.net_worth:.2f} (Œî {(self.net_worth / previous_net_worth - 1) * 100:+.2f}%)")
            print("-" * 50)

        return final_reward



    def render(self):
        console = Console()
        table = Table(show_header=True, header_style="bold magenta", show_lines=False)

        # Columns
        table.add_column("Step", style="cyan")
        table.add_column("Time", style="white")
        table.add_column("Net Worth", justify="right")
        table.add_column("Œî%", justify="right")
        table.add_column("Balance", justify="right")
        table.add_column("Stock", justify="right")
        table.add_column("Entry", justify="right")
        table.add_column("SL", justify="right")
        table.add_column("TP", justify="right")
        table.add_column("TSL", justify="center")
        table.add_column("Fees", justify="right")
        table.add_column("Action", justify="center")

        # Safe time
        try:
            current_time = pd.to_datetime(self.df.index)[self.current_step].strftime('%Y-%m-%d %H:%M')
        except Exception:
            if 'Gmt time' in self.df.columns:
                current_time = pd.to_datetime(
                    self.df.iloc[self.current_step]['Gmt time']
                ).strftime('%Y-%m-%d %H:%M')
            else:
                current_time = f"{self.current_step}"

        # Compute metrics
        net_worth_change = ((self.net_worth - self.initial_balance) / self.initial_balance) * 100
        pnl_color = "green" if net_worth_change >= 0 else "red"
        current_sl = getattr(self.risk_manager, "current_stop_loss", np.nan)
        current_tp = getattr(self.risk_manager, "current_take_profit", np.nan)
        tsl_active = getattr(self.risk_manager, "tsl_activated", False)
        entry_display = (
            f"{self.entry_price:,.2f}" if not math.isclose(self.stock_quantity, 0.0, abs_tol=1e-9) else "‚Äî"
        )

        table.add_row(
            str(self.current_step),
            current_time,
            f"${self.net_worth:,.2f}",
            Text(f"{net_worth_change:+.2f}%", style=pnl_color),
            f"${self.balance:,.2f}",
            f"{self.stock_quantity:.4f}",
            entry_display,
            f"${current_sl:,.2f}",
            f"${current_tp:,.2f}",
            "‚úÖ" if tsl_active else "‚Äî",
            f"${self.total_fees_paid:,.2f}",
            self.trade_details.get("action_taken", "N/A"),
        )

        console.print(table)

    def close(self):
        print("DEBUG ENV: Environment closed.")

    def reset(self, seed: int = None, options: dict = None):
        """
        Resets the trading environment to its initial state before a new episode.
        Returns the first observation and info dict (Gymnasium API standard).
        """
        super().reset(seed=seed)

        # --- 1Ô∏è‚É£ Reset financial state ---
        self.balance = float(self.initial_balance)
        self.net_worth = float(self.initial_balance)
        self.stock_quantity = 0.0
        self.entry_price = np.nan

        # --- 2Ô∏è‚É£ Reset Risk Manager and statistics ---
        if hasattr(self, "risk_manager") and self.risk_manager is not None:
            self.risk_manager.reset()

        self.total_trades = 0
        self.winning_trades = 0
        self.losing_trades = 0
        self.total_fees_paid_episode = 0.0
        self.trade_history_summary = deque(maxlen=1000)
        self.history = deque(maxlen=1000)

        # --- 3Ô∏è‚É£ Reset behavioral trackers ---
        self.last_action = 0
        self.actual_action_executed = 0

        # --- 4Ô∏è‚É£ Advanced reward trackers ---
        self.previous_nav = self.initial_balance
        self.peak_nav = self.initial_balance
        self.previous_drawdown_level = 0.0
        self.current_leverage = 0.0
        self.current_hold_duration = 0
        self.transaction_cost_incurred_step = 0.0
        self.traded_value_step = 0.0

        # --- 5Ô∏è‚É£ Episode boundaries ---
        min_possible_step = int(self.lookback_window_size - 1)
        max_valid_start_idx_for_obs = int(len(self.df) - 1 - min_possible_step)

        if max_valid_start_idx_for_obs <= min_possible_step:
            raise ValueError(
                f"‚ùå Not enough data to form a valid episode with the given lookback window "
                f"({self.lookback_window_size}). Data length: {len(self.df)}"
            )

        # Use the Gymnasium RNG for reproducibility
        self.start_idx = int(
            self.np_random.integers(min_possible_step, max_valid_start_idx_for_obs + 1)
        )

        # Ensure step indices are pure Python ints
        self.current_step = int(self.start_idx)
        self.max_steps = int(len(self.df) - 1 - self.start_idx)
        self.end_idx = int(self.start_idx + self.max_steps)

        # --- 6Ô∏è‚É£ Initial observation and info ---
        observation = self._get_obs()
        info = self._get_info()
        if self.trade_logger and self.episode_count > 0:
            self.trade_logger.log_episode_summary({
                'episode': self.episode_count,
                'total_reward': self.episode_reward,
                'total_trades': self.total_trades,
                'winning_trades': self.winning_trades,
                'final_balance': self.balance
            })
        self.episode_count += 1
        self.episode_reward = 0.0
        # Optional: early print or debug log
        # print(f"üîÅ Environment reset at index {self.start_idx} (Step range: {self.start_idx}-{self.end_idx})")

        return observation, info
